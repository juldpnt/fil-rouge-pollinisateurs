{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import setup_env_path\n",
    "\n",
    "setup_env_path()\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import missingno as msno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_keys = [\n",
    "    \"2b10Me1HF0rfjoGWCseolNa8e\",\n",
    "    \"2b10Xs7brWPuBdRTSeWx9V7HJu\",\n",
    "    \"2b10umm8L2jTYjlWrJKPfshJ0O\",\n",
    "    \"2b10sEg5pSsrtVT372XqlrzcLe\",\n",
    "    \"2b10LDWWlXJwuS6FleaqfK6Rke\",\n",
    "    \"2b10BoBZKV8WqZx9XCYulKvdu\",\n",
    "    \"2b10U9ilY13D9JvF70m7WjK1kO\",\n",
    "    \"2b101ARTX7UKqG1hqaeL9qav\",\n",
    "    \"2b10Aun0VZ0L3WxrRmMRtx6rsO\",\n",
    "    \"2b10PHd7xZZfWqzPghtBrYY6Me\",\n",
    "    \"2b10uRbRzoHPIDpZaY3ID9o4e\",\n",
    "    \"2b104GXJh341DO2S60qo3ABkI\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a 500 requêtes PlantNet par clef API chaque jour."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données\n",
    "\n",
    "### sauter cette partie si les fichiers csv existent déjà dans temporary_data/plantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A l'origine cette partie a été utilisée pour générer les datasets qui sont maintenant présents dans data/temporary_data/plantes. Ainsi, à moins de devoir recommencer de zéro, il n'est plus nécessaire d'executer ce code (mais il peut aider à comprendre le contenu des deux datasets construits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import spipoll.csv as a pandas dataframe\n",
    "spipoll = pd.read_csv(\"././data/spipoll.csv\",low_memory=False)\n",
    "\n",
    "# Extract relevant columns from the spipoll dataframe\n",
    "plantes = spipoll[['collection_id', 'plante_sc', 'plante_fr',\n",
    "       'plante_precision', 'plante_inconnue', 'plante_caractere',\n",
    "       'photo_fleur', 'photo_plante', 'photo_feuille']]\n",
    "\n",
    "# Shrinking the data by grouping by collection_id\n",
    "# Keep only the first row for each unique value of collection_id\n",
    "plantes = plantes.drop_duplicates(subset='collection_id', keep='first')\n",
    "\n",
    "plantes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_check = [\"Je ne sais pas\", \"Plante inconnue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantes_sc_unlabelled = plantes.loc[\n",
    "    (\n",
    "        (plantes[\"plante_sc\"].isna() | plantes[\"plante_sc\"].isin(values_to_check))\n",
    "    )\n",
    "    | ((plantes[\"plante_inconnue\"] == 1.0))\n",
    "]\n",
    "\n",
    "# creation du dataframe contenant les valeurs de plantes mais pas de plantes_sc_unlabelled\n",
    "plantes_sc_labelled = plantes[~plantes.index.isin(plantes_sc_unlabelled.index)]\n",
    "\n",
    "plantes_sc_labelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification des dimensions des deux df par rapport à la dim de plantes\n",
    "plantes_sc_labelled.shape[0] + plantes_sc_unlabelled.shape[0] == plantes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantes_precision_unlabelled = plantes_sc_unlabelled.loc[\n",
    "    (\n",
    "        (plantes[\"plante_precision\"].isna() | plantes[\"plante_precision\"].isin(values_to_check))\n",
    "    )\n",
    "]\n",
    "\n",
    "# creation du dataframe contenant les valeurs de plantes_sc_unlabelled mais pas de plantes_precision_unlabelled\n",
    "plantes_precision_labelled = plantes_sc_unlabelled[~plantes_sc_unlabelled.index.isin(plantes_precision_unlabelled.index)]\n",
    "\n",
    "plantes_precision_labelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verification des dimensions des deux df par rapport à la dim de plantes_sc_unlabelled\n",
    "plantes_precision_labelled.shape[0] + plantes_precision_unlabelled.shape[0] == plantes_sc_unlabelled.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compression de l'information étiquettée redondante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group plantes_sc_labelled by unique values of plante_sc\n",
    "plantes_sc_labelled = plantes_sc_labelled.drop_duplicates(subset='plante_sc', keep='first')\n",
    "\n",
    "# display the dimension of the dataframe\n",
    "plantes_sc_labelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group plantes_precision_labelled by unique values of plante_precision\n",
    "plantes_precision_labelled = plantes_precision_labelled.drop_duplicates(subset='plante_precision', keep='first')\n",
    "\n",
    "# display the dimension of the dataframe\n",
    "plantes_precision_labelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajoute trois colonnes après plante_sc dans le dataframe plantes_sc_labelled \"Famille\", \"Genre\" et \"Espèce\" entre la colonne plante_sc et plante_fr\n",
    "plantes_sc_labelled.insert(2, \"Famille\", \"\")\n",
    "plantes_sc_labelled.insert(3, \"Genre\", \"\")\n",
    "plantes_sc_labelled.insert(4, \"Espece\", \"\")\n",
    "\n",
    "# ajoute trois colonnes après plante_sc dans le dataframe plantes_precision_labelled \"Famille\", \"Genre\" et \"Espèce\" entre la colonne plante_sc et plante_fr\n",
    "plantes_precision_labelled.insert(2, \"Famille\", \"\")\n",
    "plantes_precision_labelled.insert(3, \"Genre\", \"\")\n",
    "plantes_precision_labelled.insert(4, \"Espece\", \"\")\n",
    "\n",
    "# ajoute trois colonnes après plante_sc dans le dataframe plantes_precision_unlabelled \"Famille\", \"Genre\" et \"Espèce\" entre la colonne plante_sc et plante_fr\n",
    "plantes_precision_unlabelled.insert(2, \"Famille\", \"\")\n",
    "plantes_precision_unlabelled.insert(3, \"Genre\", \"\")\n",
    "plantes_precision_unlabelled.insert(4, \"Espece\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appel à l'API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_quality.plant_treatment.plantnet_api import PlantNetPredictor\n",
    "\n",
    "def call_API(df, iloc, api_key_index=0):\n",
    "    \n",
    "    predictor = PlantNetPredictor(key = API_keys[api_key_index])\n",
    "    prediction = None\n",
    "\n",
    "    try:\n",
    "        prediction = predictor.predict(imageURL= df['photo_fleur'].iloc[iloc],\n",
    "                        organs = \"auto\",\n",
    "                        includeRelatedImages=False)\n",
    "    except Exception as e:\n",
    "        if api_key_index + 1 < len(API_keys):\n",
    "            return call_API(df, iloc, api_key_index + 1)\n",
    "        else:\n",
    "            print(f\"Error: {e}\")\n",
    "            return [\"erreur_API\", \"erreur_API\", \"erreur_API\"]\n",
    "\n",
    "    try:\n",
    "        famille = prediction[\"results\"][0][\"species\"][\"family\"][\"scientificNameWithoutAuthor\"] # famille\n",
    "        genre = prediction[\"results\"][0][\"species\"][\"genus\"][\"scientificNameWithoutAuthor\"] # genre\n",
    "        espece = prediction[\"results\"][0][\"species\"][\"scientificNameWithoutAuthor\"] # espece\n",
    "    \n",
    "    except IndexError:\n",
    "        print(\"IndexError: list index out of range\")\n",
    "        return [\"erreur_API\", \"erreur_API\", \"erreur_API\"]\n",
    "\n",
    "    return [famille, genre, espece]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplir_tableau(df, num):\n",
    "    \n",
    "    for i in tqdm(range(num)):\n",
    "        start_index = 0\n",
    "\n",
    "        for j, val in enumerate(df[\"Famille\"]):\n",
    "            if val == \"\":\n",
    "                start_index = j\n",
    "                break\n",
    "        else:\n",
    "            print(\"Le dataframe est déjà rempli.\")\n",
    "            return df\n",
    "\n",
    "        try:\n",
    "            df.iloc[start_index, 2:5] = call_API(df,start_index)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Un petit POC (pas nécessaire pour la suite)\n",
    "\n",
    "### sauter cette partie si les fichiers csv existent déjà dans temporary_data/plantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remplir_tableau(plantes_sc_labelled, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantes_sc_labelled.head(15) # verification des 7 premières lignes remplies et 3 suivantes non remplies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (uniquement utile pour faire des tests) vide les colonnes \"Famille\", \"Genre\" et \"Espece\" du dataframe plantes_sc_labelled\n",
    "plantes_sc_labelled.iloc[:, 2:5] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantes_sc_labelled.shape # verification du maintien de la dimension du dataframe : OK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut environ 3 secondes pour un call API, soit environ 2h10 pour les 2620 plantes à traiter dans plantes_sc_labelled.\n",
    "\n",
    "On va donc stocker le dataframe dans un csv entre chaque appel à l'API pour ne pas perdre le travail effectué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df, df_name):\n",
    "    df.to_csv(f\"data/temporary_data/plantes/{df_name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_dataframe(df_name):\n",
    "    return pd.read_csv(f\"data/temporary_data/plantes/{df_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plantes_sc_labelled = import_dataframe(\"plantes_sc_labelled\")\n",
    "plantes_precision_labelled = import_dataframe(\"plantes_precision_labelled\")\n",
    "plantes_precision_unlabelled = import_dataframe(\"plantes_precision_unlabelled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_remplissage(df_name, num):\n",
    "    df = import_dataframe(df_name)\n",
    "    df[[\"Famille\", \"Genre\", \"Espece\"]] = df[[\"Famille\", \"Genre\", \"Espece\"]].fillna(\"\")\n",
    "    remplir_tableau(df, num)\n",
    "    save_dataframe(df, df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POC\n",
    "# pipeline_remplissage(\"plantes_precision_unlabelled\", 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sauvegarde progressive des calls API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(df_name, n):\n",
    "    for i in range(n):\n",
    "        try:\n",
    "            pipeline_remplissage(df_name, 10) # une itération prend 30 secondes\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred after {i} successful runs: {e}\")\n",
    "            break   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permet d'effectuer une sauvegarde des telechargements toutes les 10 occurences ie toutes les 30 secondes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline('plantes_precision_unlabelled', 26)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verification de la progression des téléchargements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verification_progression(df_name):\n",
    "    # importe le dataframe plantes_sc_labelled depuis le fichier csv\n",
    "    df = pd.read_csv(f\"data/temporary_data/plantes/{df_name}.csv\")\n",
    "    # utilise missingno pour visualiser les valeurs manquantes dans le dataframe\n",
    "    msno.matrix(df)\n",
    "    \n",
    "    # estimation de la quantité de travail restante en téléchargement de données\n",
    "    num_nan = df[\"Famille\"].isna().sum()\n",
    "    percent_nan = round((num_nan / len(df)) * 100,2)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Nombre de lignes dans 'Famille' restants à télécharger : {num_nan}\")\n",
    "    print(f\"Pourcentage de lignes dans 'Famille' restants à télécharger : {percent_nan} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importe plantes_precision_unlabelled depuis le fichier csv\n",
    "plantes_precision_unlabelled = import_dataframe(\"plantes_precision_unlabelled\")\n",
    "# toutes les lignes de famille genre espece conteant \"erreur_API\" doivent être vidées avec \"\"\n",
    "plantes_precision_unlabelled[[\"Famille\", \"Genre\", \"Espece\"]] = plantes_precision_unlabelled[[\"Famille\", \"Genre\", \"Espece\"]].replace(\"erreur_API\", \"\")\n",
    "# sauvegarde le dataprecisioname dans un fichier csv\n",
    "save_dataframe(plantes_precision_unlabelled, \"plantes_precision_unlabelled\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_progression('plantes_precision_unlabelled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_plantes(nom_df):\n",
    "    # Importer le dataframe\n",
    "    df = pd.read_csv(f\"data/temporary_data/plantes/{nom_df}.csv\")\n",
    "\n",
    "    # Vérifier si la colonne \"Famille\" contient des valeurs NaN\n",
    "    if df[\"Famille\"].isna().any():\n",
    "        num_nan = df[\"Famille\"].isna().sum()\n",
    "        percent_nan = round((num_nan / len(df)) * 100,2)\n",
    "        print(\"Il reste\", percent_nan,\"% des données à télécharger, soit\", num_nan,\"lignes.\")\n",
    "        msno.matrix(df)\n",
    "    else:\n",
    "        # Sauvegarder le dataframe dans un fichier CSV\n",
    "        df.to_csv(f\"data/plantes/{nom_df}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_plantes('plantes_precision_unlabelled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Décompression des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to do : quand les 3 dataframes seront telechargées à 100 % "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
